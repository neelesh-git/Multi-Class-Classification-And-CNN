{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - One Hidden Layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the dataset\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Oct 15 02:06:32 2019\n",
    "\n",
    "@author: neeleshbhajantri\n",
    "\"\"\"\n",
    "\n",
    "# Read Fashion MNIST dataset\n",
    "\n",
    "import util_mnist_reader as mnist_reader\n",
    "x_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "x_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m_train = 60000\n",
    "m_test = 10000\n",
    "\n",
    "mask = list(range(m_train))\n",
    "x_train = x_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "mask = list(range(m_test))\n",
    "x_test = x_test[mask]\n",
    "y_test = y_test[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping to rows\n",
    "x_train = x_train.reshape(60000, -1)\n",
    "x_test = x_test.reshape(10000, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a class with fucntions of predict() relu() train)() loss function()\n",
    "class NN(object):\n",
    "    \n",
    "    def __init__(self, in_size, h_size, out_size, std=1e-4):\n",
    "        self.params = {}    \n",
    "        self.params['w1'] = std * np.random.randn(in_size, h_size)   \n",
    "        self.params['b1'] = np.zeros((1, h_size))\n",
    "        self.params['w2'] = std * np.random.randn(h_size, out_size)   \n",
    "        self.params['b2'] = np.zeros((1, out_size))\n",
    "        \n",
    "    def loss_func(self, x, y = None, reg = 0.0):\n",
    "        w1, b1 = self.params['w1'], self.params['b1']\n",
    "        w2, b2 = self.params['w2'], self.params['b2']\n",
    "        N, D = x.shape\n",
    "        \n",
    "        score = None\n",
    "        #print(w1.shape)\n",
    "        h1 = self.ReLU(np.dot(x, w1) + b1)\n",
    "        output = np.dot(h1, w2) + b2\n",
    "        score = output\n",
    "        \n",
    "        if y is None:\n",
    "            return score\n",
    "        max_score = np.max(score, axis=1, keepdims=True)\n",
    "        exp_score = np.exp(score - max_score)\n",
    "        probs = exp_score / np.sum(exp_score, axis=1, keepdims=True)\n",
    "        correct_N = -np.log(probs[range(N), y])\n",
    "        lost_data = np.sum(correct_N) / N\n",
    "        reg_loss = 0.5 * reg * np.sum(w1*w1) + 0.5 * reg * np.sum(w2*w2)\n",
    "        loss = lost_data + reg_loss\n",
    "\n",
    "        #backward propogation\n",
    "\n",
    "        grads = {}\n",
    "        dscores = probs                                 \n",
    "        dscores[range(N), y] -= 1\n",
    "        dscores /= N\n",
    "        dw2 = np.dot(h1.T, dscores)                     \n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)    \n",
    "        dh1 = np.dot(dscores, w2.T)                     \n",
    "        dh1[h1 <= 0] = 0\n",
    "        dw1 = np.dot(x.T, dh1)                          \n",
    "        db1 = np.sum(dh1, axis=0, keepdims=True)        \n",
    "        dw2 += reg * w2\n",
    "        dw1 += reg * w1\n",
    "\n",
    "        grads['w1'] = dw1\n",
    "        grads['b1'] = db1\n",
    "        grads['w2'] = dw2\n",
    "        grads['b2'] = db2\n",
    "\n",
    "        return loss, grads\n",
    "    \n",
    "    def train(self, x, y, x_test, y_test, learning_rate = 1e-3, \n",
    "               learning_rate_decay = 0.95, reg = 1e-5, mu = 0.9, epoch_no = 10, \n",
    "               mu_increase = 1.0, batch_size = 200, verbose = False):\n",
    "               train_no = x.shape[0]\n",
    "               iterations = max(int(train_no / batch_size), 1)\n",
    "               v_w2, v_b2 = 0.0, 0.0\n",
    "               v_w1, v_b1 = 0.0, 0.0\n",
    "               loss_history = []\n",
    "               train_acc_history = []\n",
    "               test_acc_history = []\n",
    "            \n",
    "               for i in range(1, epoch_no * iterations + 1):\n",
    "                   x_batch = None\n",
    "                   y_batch = None\n",
    "                   sample_index = np.random.choice(train_no, batch_size, replace=True)   \n",
    "                   x_batch = x[sample_index, :]          \n",
    "                   y_batch = y[sample_index]\n",
    "                   loss, grads = self.loss_func(x_batch, y=y_batch, reg=reg) \n",
    "                   loss_history.append(loss)\n",
    "                   v_w2 = mu * v_w2 - learning_rate * grads['w2']\n",
    "                   self.params['w2'] += v_w2   \n",
    "                   v_b2 = mu * v_b2 - learning_rate * grads['b2']    \n",
    "                   self.params['b2'] += v_b2   \n",
    "                   v_w1 = mu * v_w1 - learning_rate * grads['w1']    \n",
    "                   self.params['w1'] += v_w1   \n",
    "                   v_b1 = mu * v_b1 - learning_rate * grads['b1']  \n",
    "                   self.params['b1'] += v_b1\n",
    "\n",
    "                   if verbose and i % iterations == 0:\n",
    "                       epoch = i/iterations\n",
    "                       train_acc = (self.predict(x_batch) == y_batch).mean()\n",
    "                       test_acc = (self.predict(x_test) == y_test).mean()\n",
    "                       train_acc_history.append(train_acc)\n",
    "                       test_acc_history.append(test_acc)\n",
    "                       learning_rate = learning_rate * learning_rate_decay\n",
    "                       mu = mu * mu_increase\n",
    "               return {'loss_history': loss_history, \n",
    "               'train_acc_history': train_acc_history, \n",
    "               'test_acc_history': test_acc_history}\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_pred = None\n",
    "        h1 = self.ReLU(np.dot(x, self.params['w1']) + self.params['b1'])\n",
    "        score = np.dot(h1, self.params['w2']) + self.params['b2']\n",
    "        y_pred = np.argmax(score, axis = 1)\n",
    "        return y_pred\n",
    "    \n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predection and plotting\n",
    "in_size = x_train.shape[1]\n",
    "h_size = 10\n",
    "no_classes = 10\n",
    "call = NN(in_size, h_size, no_classes)\n",
    "\n",
    "history = call.train(x_train, y_train, x_test, y_test, epoch_no = 1000, batch_size = 500, \n",
    "learning_rate = 7.5e-4, learning_rate_decay = 0.9, reg = 1.0, verbose = True)\n",
    "test_acc = (call.predict(x_test) == y_test).mean()\n",
    "print(test_acc)\n",
    "# Plot the loss function and train / validation accuracies\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history['train_acc_history'], label='train')\n",
    "plt.plot(history['test_acc_history'], label='val')\n",
    "#plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Multiple hidden layer NN with Kears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here . . .\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 180\n",
    "class_no = 10\n",
    "epochs = 30\n",
    "#Pre processing the data\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "y_train = keras.utils.to_categorical(y_train, class_no)\n",
    "y_test = keras.utils.to_categorical(y_test, class_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Designing the model with sequential()\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation = 'relu', input_shape = (784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(class_no, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(), metrics = ['accuracy'])\n",
    "history = model.fit(x_train, y_train,  batch_size = batch_size, \n",
    "                    epochs = epochs, verbose = 1, \n",
    "                    validation_data = (x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "#Printing the test loss and Accuracy\n",
    "print(\"Test Loss\", score[0])\n",
    "print(\"Test Accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Convolution NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the data\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "batch_size = 180\n",
    "class_no = 10\n",
    "epochs = 30\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "#y_train = y_train.reshape(60000, 1,)\n",
    "#y_test = y_test.reshape(10000, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, class_no)\n",
    "y_test = keras.utils.to_categorical(y_test, class_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size = 2, padding = 'same', activation = 'relu',\n",
    "                 input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = 2, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(class_no, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = Adam(), metrics = ['accuracy'])\n",
    "history = model.fit(x_train, y_train,  batch_size = batch_size, \n",
    "                    epochs = epochs, verbose = 1, \n",
    "                    validation_data = (x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "#Printing test loss and accuracy\n",
    "print(\"Test Loss\", score[0])\n",
    "print(\"Test Accuracy\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
